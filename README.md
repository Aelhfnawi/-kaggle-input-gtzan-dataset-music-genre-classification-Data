# ğŸ¶ Music Genre Classification using Spectrograms ğŸ§

This project focuses on classifying music genres using deep learning techniques applied to **audio spectrograms** extracted from the [GTZAN Dataset](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification).

## ğŸ“‚ Dataset
- **Source**: GTZAN Dataset
- **Classes**: 10 Genres (e.g. Rock, Jazz, Classical, Hip-Hop, etc.)
- **Data Format**: Audio files were converted into spectrogram images using Mel-spectrogram representation.
- **Path**: `/content/gtzan-dataset-music-genre-classification/Data/images_original`

## ğŸ§  Model Pipeline

1. **Preprocessing**: Convert audio files to spectrogram images.
2. **Data Augmentation**: (Optional) Enhance training set with image transformations.
3. **Modeling**: CNN-based architecture for image classification.
4. **Evaluation**: Accuracy, confusion matrix, classification report.

## ğŸ› ï¸ Tech Stack
- Python
- TensorFlow / Keras
- Librosa (for audio processing)
- Matplotlib (for spectrogram generation)
- Scikit-learn (for metrics)

## ğŸ† Results
Achieved promising accuracy in classifying music genres visually via spectrograms â€” turning sounds into sight and letting the model *listen with its eyes*.

## ğŸš€ Future Improvements
- Try MFCCs and raw audio waveform input
- Experiment with pre-trained CNNs (ResNet, VGG)
- Use audio embeddings or Transformer-based audio models

---

## ğŸ“Œ Project Status
âœ… Notebook completed  
ğŸ§ª Model tested  
ğŸ“ˆ Evaluation metrics analyzed  

---

## ğŸ“¸ Sample Spectrogram
*(Include an image of a spectrogram or your model architecture if possible)*

---

## ğŸ“¬ Contact
Made with ğŸ§ by **Ahmed Elhfnawi**  
[GitHub](https://github.com/Aelhfnawi) | [LinkedIn](https://www.linkedin.com/in/ahmed-elhfnawi)

