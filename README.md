# 🎶 Music Genre Classification using Spectrograms 🎧

This project focuses on classifying music genres using deep learning techniques applied to **audio spectrograms** extracted from the [GTZAN Dataset](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification).

## 📂 Dataset
- **Source**: GTZAN Dataset
- **Classes**: 10 Genres (e.g. Rock, Jazz, Classical, Hip-Hop, etc.)
- **Data Format**: Audio files were converted into spectrogram images using Mel-spectrogram representation.
- **Path**: `/content/gtzan-dataset-music-genre-classification/Data/images_original`

## 🧠 Model Pipeline

1. **Preprocessing**: Convert audio files to spectrogram images.
2. **Data Augmentation**: (Optional) Enhance training set with image transformations.
3. **Modeling**: CNN-based architecture for image classification.
4. **Evaluation**: Accuracy, confusion matrix, classification report.

## 🛠️ Tech Stack
- Python
- TensorFlow / Keras
- Librosa (for audio processing)
- Matplotlib (for spectrogram generation)
- Scikit-learn (for metrics)

## 🏆 Results
Achieved promising accuracy in classifying music genres visually via spectrograms — turning sounds into sight and letting the model *listen with its eyes*.

## 🚀 Future Improvements
- Try MFCCs and raw audio waveform input
- Experiment with pre-trained CNNs (ResNet, VGG)
- Use audio embeddings or Transformer-based audio models

---

## 📌 Project Status
✅ Notebook completed  
🧪 Model tested  
📈 Evaluation metrics analyzed  

---

## 📸 Sample Spectrogram
*(Include an image of a spectrogram or your model architecture if possible)*

---

## 📬 Contact
Made with 🎧 by **Ahmed Elhfnawi**  
[GitHub](https://github.com/Aelhfnawi) | [LinkedIn](https://www.linkedin.com/in/ahmed-elhfnawi)

